[
  {
    "objectID": "VT0007-deforestation-map.html",
    "href": "VT0007-deforestation-map.html",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "",
    "text": "Two workflow approaches are detailed below following similar steps to those outlined in Verra’s recommended sequence of deforestation risk map development Verra (2021). For comparison purposes, both workflows are derived using same sources of training sample dataset (Stanimirova et al. 2023) and collection of STAC-formatted analysis-ready-data of Landsat imagery.\nWorkflow-1 is coded within the R ecosystem and is recommended for smaller areas of analysis, as it offers additional functions for model tuning and classifer evaluation. Workflow-2, which is coded using Python and Google Earth Engine functions, is recommended for larger areas of interest ( (Java transcription pending, link here).\n\n\n\nFigure 1: Verra’s recommended risk map development sequence (VT0007:6)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#summary",
    "href": "VT0007-deforestation-map.html#summary",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "",
    "text": "Two workflow approaches are detailed below following similar steps to those outlined in Verra’s recommended sequence of deforestation risk map development Verra (2021). For comparison purposes, both workflows are derived using same sources of training sample dataset (Stanimirova et al. 2023) and collection of STAC-formatted analysis-ready-data of Landsat imagery.\nWorkflow-1 is coded within the R ecosystem and is recommended for smaller areas of analysis, as it offers additional functions for model tuning and classifer evaluation. Workflow-2, which is coded using Python and Google Earth Engine functions, is recommended for larger areas of interest ( (Java transcription pending, link here).\n\n\n\nFigure 1: Verra’s recommended risk map development sequence (VT0007:6)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#process-data-cube",
    "href": "VT0007-deforestation-map.html#process-data-cube",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "Process data cube",
    "text": "Process data cube\nFor shawcasing purposes, we import a training dataset from the sitsdata package from a study of Brazil’s Samuel Hydroelectric Dam in Rondonia State conducted between 2020-06-04 to 2021-08-26. To evaluate this training sample, we assemble below a data cube of Sentinel-2-L2A-COGS images from the AWS open bucket. Raster normalization is implemented with sits_regularize functions to apply a cloud masking and back-filling of missing pixels by cloudless ranking and global median values across 16-day intervals.\n\n# build irregular data cube from single sentinel tile\ns2_cube_ro &lt;- sits_cube(\n  source = \"AWS\",\n  collection = \"SENTINEL-S2-L2A-COGS\",\n  tiles = \"20LMR\",\n  bands = c(\"B02\", \"B8A\", \"B11\", \"SCL\"),\n  start_date = as.Date(\"2020-06-01\"),\n  end_date = as.Date(\"2021-09-01\"),\n  progress = FALSE)\n\n\n  |                                                                            \n  |======================================================================| 100%\n\n# select aoi inside the tile\nroi &lt;- c(\n  lon_max = -63.25790, lon_min = -63.6078,\n  lat_max = -8.72290, lat_min = -8.95630)\n\n# regularize the aoi filtered cube\ns2_reg_cube_ro &lt;- sits_regularize(\n  cube = s2_cube_ro,\n  output_dir = \"./cubes/01_reg\",\n  res = 30,\n  roi = roi,\n  period = \"P16D\",\n  memsize = 16,\n  multicores = 4,\n  progress = FALSE)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#review-data-cube",
    "href": "VT0007-deforestation-map.html#review-data-cube",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "Review data cube",
    "text": "Review data cube\nplot(s2_reg_cube_ro,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  date = \"2020-07-04\"\n  )\nplot(s2_reg_cube_ro,\n  red = \"B11\",\n  green = \"B8A\",\n  blue = \"B02\",\n  date = \"2020-11-09\"\n  )\nplot(s2_reg_cube_ro, \n     red = \"B11\", \n     green = \"B8A\", \n     blue = \"B02\", \n     date = \"2021-08-08\"\n     )"
  },
  {
    "objectID": "VT0007-deforestation-map.html#classify-data-cube",
    "href": "VT0007-deforestation-map.html#classify-data-cube",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "Classify data cube",
    "text": "Classify data cube\nWe import a training set of 480 times series points specifically designed to detect deforestation, which comprise of four classes (Burned_Area, Forest, Highly_Degraded, and Cleared_Area). Training samples are fitted to a Random Forest model and post-processed with a Bayesian smoothing.\n\n# Load the training set\nglance_training = \"https://drive.google.com/file/d/1CgBP2J2OdOhmOiVS4hGibLEMyVLTe1_P/view?usp=drive_link\"\ndata(\"samples_prodes_4classes\")\n# Select the same three bands used in the data cube\nsamples_4classes_3bands &lt;- sits_select(\n  data = samples_prodes_4classes,\n  bands = c(\"B02\", \"B8A\", \"B11\")\n  )\n\n# Train a random forest model\nrfor_model &lt;- sits_train(\n  samples = samples_4classes_3bands,\n  ml_method = sits_rfor()\n  )\n\n# Classify the small area cube\ns2_cube_probs &lt;- sits_classify(\n  data = s2_reg_cube_ro,\n  ml_model = rfor_model,\n  output_dir = \"./cubes/02_class/\",\n  memsize = 15,\n  multicores = 5\n  )\n\n# Post-process the probability cube\ns2_cube_bayes &lt;- sits_smooth(\n  cube = s2_cube_probs,\n  output_dir = \"./cubes/02_class/\",\n  memsize = 16,\n  multicores = 4\n  )\n\n# Label the post-processed  probability cube\ns2_cube_label &lt;- sits_label_classification(\n  cube = s2_cube_bayes,\n  output_dir = \"./cubes/02_class/\",\n  memsize = 16,\n  multicores = 4\n  )\n\nplot(s2_cube_label)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#map-uncertainty",
    "href": "VT0007-deforestation-map.html#map-uncertainty",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "Map uncertainty",
    "text": "Map uncertainty\nTo improve model performance, we estimate class uncertainty and plot these pixel error metrics. Results below reveal highest uncertainty levels in classification of wetland and water areas.\n\n# Calculate the uncertainty cube\ns2_cube_uncert &lt;- sits_uncertainty(\n  cube = s2_cube_bayes,\n  type = \"margin\",\n  output_dir = \"./cubes/03_error/\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_uncert)\n\n\n\n\n\n\n\n\nAs expected, the places of highest uncertainty are those covered by surface water or associated with wetlands. These places are likely to be misclassified. For this reason, sits provides sits_uncertainty_sampling(), which takes the uncertainty cube as its input and produces a tibble with locations in WGS84 with high uncertainty (Camara et al., n.d.).\n\n# Find samples with high uncertainty\nnew_samples &lt;- sits_uncertainty_sampling(\n  uncert_cube = s2_cube_uncert,\n  n = 20,\n  min_uncert = 0.5,\n  sampling_window = 10\n  )\n\n# View the location of the samples\nsits_view(new_samples)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#add-training-samples",
    "href": "VT0007-deforestation-map.html#add-training-samples",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "Add training samples",
    "text": "Add training samples\nWe can then use these points of high-uncertainty as new samples to add to our current training dataset. Once we identify their feature classes and relabel them correctly, we append them to derive an augmented samples_round_2.\n\n# Label the new samples\nnew_samples$label &lt;- \"Wetland\"\n\n# Obtain the time series from the regularized cube\nnew_samples_ts &lt;- sits_get_data(\n  cube = s2_reg_cube_ro,\n  samples = new_samples\n  )\n\n# Add new class to original samples\nsamples_round_2 &lt;- dplyr::bind_rows(\n  samples_4classes_3bands,\n  new_samples_ts\n  )\n\n# Train a RF model with the new sample set\nrfor_model_v2 &lt;- sits_train(\n  samples = samples_round_2,\n  ml_method = sits_rfor()\n  )\n\n# Classify the small area cube\ns2_cube_probs_v2 &lt;- sits_classify(\n  data = s2_reg_cube_ro,\n  ml_model = rfor_model_v2,\n  output_dir = \"./cubes/02_class/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n  )\n\n# Post-process the probability cube\ns2_cube_bayes_v2 &lt;- sits_smooth(\n  cube = s2_cube_probs_v2,\n  output_dir = \"./cubes/04_smooth/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n  )\n\n# Label the post-processed  probability cube\ns2_cube_label_v2 &lt;- sits_label_classification(\n  cube = s2_cube_bayes_v2,\n  output_dir = \"./cubes/05_tuned/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n  )\n\n# Plot the second version of the classified cube\nplot(s2_cube_label_v2)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#remap-uncertainty",
    "href": "VT0007-deforestation-map.html#remap-uncertainty",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "Remap uncertainty",
    "text": "Remap uncertainty\n\n# Calculate the uncertainty cube\ns2_cube_uncert_v2 &lt;- sits_uncertainty(\n  cube = s2_cube_bayes_v2,\n  type = \"margin\",\n  output_dir = \"./cubes/03_error/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_uncert_v2)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#accuracy-assessment",
    "href": "VT0007-deforestation-map.html#accuracy-assessment",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "Accuracy assessment",
    "text": "Accuracy assessment\nTo select a validation subset of the map, sits recommends Cochran’s method for stratified random sampling (Cochran 1977). The method divides the population into homogeneous subgroups, or strata, and then applying random sampling within each stratum. Alternatively, ad-hoc parameterization is suggested as follows.\n\nro_sampling_design &lt;- sits_sampling_design(\n  cube = s2_cube_label_v2,\n  expected_ua = c(\n    \"Burned_Area\"       = 0.75,\n    \"Cleared_Area\"      = 0.70,\n    \"Forest\"            = 0.75,\n    \"Highly_Degraded\"   = 0.70,\n    \"Wetland\"           = 0.70\n  ),\n  alloc_options         = c(120, 100),\n  std_err               = 0.01,\n  rare_class_prop       = 0.1\n)\n# show sampling desing\nro_sampling_design\n\n                prop       expected_ua std_dev equal alloc_120 alloc_100\nBurned_Area     0.01001252 0.75        0.433   408   120       100      \nCleared_Area    0.3680405  0.7         0.458   408   702       717      \nForest          0.2445099  0.75        0.433   408   466       477      \nHighly_Degraded 0.04600642 0.7         0.458   408   120       100      \nWetland         0.3314307  0.7         0.458   408   632       646      \n                alloc_prop\nBurned_Area     20        \nCleared_Area    751       \nForest          499       \nHighly_Degraded 94        \nWetland         676"
  },
  {
    "objectID": "VT0007-deforestation-map.html#split-traintest-data",
    "href": "VT0007-deforestation-map.html#split-traintest-data",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "Split train/test data",
    "text": "Split train/test data\n\nro_samples_sf &lt;- sits_stratified_sampling(\n  cube                  = s2_cube_label_v2,\n  sampling_design       = ro_sampling_design,\n  alloc                 = \"alloc_120\",\n  multicores            = 4,\n  shp_file              = \"./samples/ro_samples.shp\"\n)\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\nDeleting layer `ro_samples' using driver `ESRI Shapefile'\nWriting layer `ro_samples' to data source \n  `./samples/ro_samples.shp' using driver `ESRI Shapefile'\nWriting 2450 features with 1 fields and geometry type Point.\n\nsf::st_write(ro_samples_sf,\n  \"./samples/ro_samples.csv\",\n  layer_options = \"GEOMETRY=AS_XY\",\n  append = FALSE # TRUE if editing existing sample\n)\n\nDeleting layer `ro_samples' using driver `CSV'\nWriting layer `ro_samples' to data source \n  `./samples/ro_samples.csv' using driver `CSV'\noptions:        GEOMETRY=AS_XY \nUpdating existing layer ro_samples\nWriting 2450 features with 1 fields and geometry type Point."
  },
  {
    "objectID": "VT0007-deforestation-map.html#confusion-matrix",
    "href": "VT0007-deforestation-map.html#confusion-matrix",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "Confusion matrix",
    "text": "Confusion matrix\n\n# Calculate accuracy according to Olofsson's method\narea_acc &lt;- sits_accuracy(s2_cube_label_v2,\n  validation = ro_samples_sf,\n  multicores = 4\n)\n# Print the area estimated accuracy\narea_acc\n\nArea Weighted Statistics\nOverall Accuracy = 1\n\nArea-Weighted Users and Producers Accuracy\n                User Producer\nBurned_Area        1        1\nCleared_Area       1        1\nForest             1        1\nHighly_Degraded    1        1\nWetland            1        1\n\nMapped Area x Estimated Area (ha)\n                Mapped Area (ha) Error-Adjusted Area (ha) Conf Interval (ha)\nBurned_Area               993.51                   993.51                  0\nCleared_Area            36519.48                 36519.48                  0\nForest                  24261.93                 24261.93                  0\nHighly_Degraded          4565.07                  4565.07                  0\nWetland                 32886.81                 32886.81                  0\n\n# Print the confusion matrix\narea_acc$error_matrix\n\n                 \n                  Burned_Area Cleared_Area Forest Highly_Degraded Wetland\n  Burned_Area             144            0      0               0       0\n  Cleared_Area              0          843      0               0       0\n  Forest                    0            0    560               0       0\n  Highly_Degraded           0            0      0             144       0\n  Wetland                   0            0      0               0     759"
  },
  {
    "objectID": "VT0007-deforestation-map.html#times-series-visualization",
    "href": "VT0007-deforestation-map.html#times-series-visualization",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "Times series visualization",
    "text": "Times series visualization\n\nsummary(as.data.frame(ro_samples_sf))\n\n    label                    geometry   \n Length:2450        POINT        :2450  \n Class :character   epsg:4326    :   0  \n Mode  :character   +proj=long...:   0"
  },
  {
    "objectID": "VT0007-deforestation-map.html#deforestation-binary-map",
    "href": "VT0007-deforestation-map.html#deforestation-binary-map",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "Deforestation binary map",
    "text": "Deforestation binary map"
  },
  {
    "objectID": "VT0007-deforestation-map.html#deforestation-risk-map",
    "href": "VT0007-deforestation-map.html#deforestation-risk-map",
    "title": "Jurisdictional Allocation & Deforestation Risk Maps",
    "section": "Deforestation risk map",
    "text": "Deforestation risk map"
  }
]