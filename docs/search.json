[
  {
    "objectID": "VT0007-deforestation-map.html",
    "href": "VT0007-deforestation-map.html",
    "title": "JNR Deforestation Risk Maps",
    "section": "",
    "text": "The following details two workflow approaches to Verra’s recommended sequence of deforestation risk map development Verra (2021). For comparison purposes, both workflows use the same training sample (Stanimirova et al. 2023) and STAC-formatted Landsat Collection-2 Level-2 imagery.\nWorkflow-1 is coded in R and is recommended for smaller areas of analysis, as it offers additional functions for model tuning and classifer evaluation. Workflow-2, which is coded in Python and Google Earth Engine functions, is recommended for larger areas of interest (Update java link here).\n\n\n\nFigure 1: Verra’s recommended risk map development sequence (VT0007:6)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#summary",
    "href": "VT0007-deforestation-map.html#summary",
    "title": "JNR Deforestation Risk Maps",
    "section": "",
    "text": "The following details two workflow approaches to Verra’s recommended sequence of deforestation risk map development Verra (2021). For comparison purposes, both workflows use the same training sample (Stanimirova et al. 2023) and STAC-formatted Landsat Collection-2 Level-2 imagery.\nWorkflow-1 is coded in R and is recommended for smaller areas of analysis, as it offers additional functions for model tuning and classifer evaluation. Workflow-2, which is coded in Python and Google Earth Engine functions, is recommended for larger areas of interest (Update java link here).\n\n\n\nFigure 1: Verra’s recommended risk map development sequence (VT0007:6)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#testing-phase",
    "href": "VT0007-deforestation-map.html#testing-phase",
    "title": "JNR Deforestation Risk Maps",
    "section": "1.1 Testing phase",
    "text": "1.1 Testing phase\n\nimport numpy as np\nimport sys \nprint(sys.executable)\n\n/home/seamus/Repos/VT0007-deforestation-map/bin/python\n\n\n\nJurisdictional boundaries\n\n# assign master crs\ncrs_master  = sf::st_crs(\"epsg:4326\")\naoi_country = geodata::gadm(country=\"GUY\", level=0, path=tempdir()) |&gt;\n  sf::st_as_sf() |&gt; sf::st_cast() |&gt; sf::st_transform(crs_master)\naoi_states = geodata::gadm(country=\"GUY\", level=1, path=tempdir()) |&gt;\n  sf::st_as_sf() |&gt; sf::st_cast() |&gt; sf::st_transform(crs_master) |&gt;\n  dplyr::rename(State = NAME_1)\naoi_target = dplyr::filter(aoi_states, State == \"Barima-Waini\")\n\ntmap::tmap_mode(\"view\")\ntmap::tm_shape(aoi_states) + tmap::tm_borders(col = \"white\", lwd = 0.5) +\n  tmap::tm_text(\"State\", col = \"white\", size = 1, alpha = 0.3, just = \"bottom\") +\n  tmap::tm_shape(aoi_country) + tmap::tm_borders(col = \"white\", lwd = 1) +\n  tmap::tm_shape(aoi_target) + tmap::tm_borders(col = \"red\", lwd = 2) +\n  tmap::tm_text(\"State\", col = \"red\", size = 1.3) +\n  tmap::tm_basemap(\"Esri.WorldImagery\")\n\n\n\n\n\n\n\nAssemble HRP time series\nWe assemble and process a data cube representing a historical reference period (HRP) between 2013-01-01 and 2023-01-01 for the country of Suriname. Using the sits_regularize functions, we apply a cloud masking and pixel back-filling based on cloudless ranking and median-normalization across 5-year intervals to derive three dry-season mosaics for 2013, 2018 and 2023.\n\n# 2014 -------------------\n# cloud-assemble data cube\ncube_raw_2014 = sits::sits_cube(\n  source      = \"MPC\",\n  collection  = \"LANDSAT-C2-L2\",\n  bands       = c(\"RED\", \"GREEN\", \"BLUE\", \"NIR08\", \"SWIR16\", \"CLOUD\"),\n  roi         = aoi_target,\n  start_date  = as.Date(\"2014-01-01\"),\n  end_date    = as.Date(\"2014-07-01\"),\n  progress    = T\n  )\n\n# regularize data cube\ncube_reg_2014 = sits::sits_regularize(\n  cube        = cube_raw_2014,\n  roi         = aoi_target,\n  res         = 60,\n  period      = \"P180D\",\n  output_dir  = here::here(\"cubes\", \"reg\", \"2014\"),\n  memsize     = 16,\n  multicores  = 8,\n  progress    = T\n  )\n\n# 2019 -------------------\n# cloud-assemble data cube\ncube_raw_2019 = sits::sits_cube(\n  source      = \"MPC\",\n  collection  = \"LANDSAT-C2-L2\",\n  bands       = c(\"RED\", \"GREEN\", \"BLUE\", \"NIR08\", \"SWIR16\", \"CLOUD\"),\n  roi         = aoi_target,\n  start_date  = as.Date(\"2019-01-01\"),\n  end_date    = as.Date(\"2019-07-01\"),\n  progress    = T\n  )\n\n# regularize data cube\ncube_reg_2019 = sits::sits_regularize(\n  cube        = cube_raw_2019,\n  roi         = aoi_target,\n  res         = 60,\n  period      = \"P180D\",\n  output_dir  = here::here(\"cubes\", \"reg\", \"2019\"),\n  memsize     = 16,\n  multicores  = 8,\n  progress    = T\n  )\n\n# 2024 -------------------\n# cloud-assemble data cube\ncube_raw_2024 = sits::sits_cube(\n  source      = \"MPC\",\n  collection  = \"LANDSAT-C2-L2\",\n  bands       = c(\"RED\", \"GREEN\", \"BLUE\", \"NIR08\", \"SWIR16\", \"CLOUD\"),\n  roi         = aoi_target,\n  start_date  = as.Date(\"2024-01-01\"),\n  end_date    = as.Date(\"2024-07-01\"),\n  progress    = T\n  )\n\n# regularize data cube\ncube_reg_2024 = sits::sits_regularize(\n  cube        = cube_raw_2024,\n  roi         = aoi_target,\n  res         = 60,\n  period      = \"P180D\",\n  output_dir  = here::here(\"cubes\", \"reg\", \"2024\"),\n  memsize     = 16,\n  multicores  = 8,\n  progress    = T\n  )\n\n# plot cube timelines\nsits_timeline(cube_reg_2014)\nsits_timeline(cube_reg_2019)\nsits_timeline(cube_reg_2024)\nplot(cube_reg_2014,\n  red         = \"RED\",\n  green       = \"GREEN\",\n  blue        = \"BLUE\",\n  date        = \"2014-01-03\"\n  )\n\nplot(cube_reg_2019,\n  red         = \"RED\",\n  green       = \"GREEN\",\n  blue        = \"BLUE\",\n  date        = \"2019-01-08\"\n  )\n\nplot(cube_reg_2024,\n  red         = \"RED\",\n  green       = \"GREEN\",\n  blue        = \"BLUE\",\n  date        = \"2024-01-07\"\n  )\n\n\n\n\n\nClassify HRP time series\nWe import the GLanCE training dataset of annual times series points that includes 7 land cover classes (Figure 2; (Woodcock et al., n.d.)). Training samples are fitted to a Random Forest model and post-processed with a Bayesian smoothing and then evaluated using confusion matrix. The classifier is then calibrated by mapping pixel uncertainty, adding new samples in areas of high uncertainty, reclassifying with improved samples and re-evaluated using confusion matrix.\n\n\n\nFigure 2: Land cover classes included in the GLanCE Level 1 classification scheme (Woodcock et al 2022)\n\n\n\n# Extract training set from gee to drive & import: https://gee-community-catalog.org/projects/glance_training/?h=training \nglance_training_url = \"https://drive.google.com/file/d/1CgBP2J2OdOhmOiVS4hGibLEMyVLTe1_P/view?usp=drive_link\"\n# file_name = \"glance_training.csv\"\n# download.file(url = url, path = here::here(\"training\"), destfile = file_name)\nglance_training = read.csv(here::here(\"training\", \"glance_training.csv\"))\n\ndata(\"samples_prodes_4classes\")\n# Select the same three bands used in the data cube\nsamples_4classes_3bands &lt;- sits_select(\n  data = samples_prodes_4classes,\n  bands = c(\"B02\", \"B8A\", \"B11\")\n  )\n\n# Train a random forest model\nrfor_model &lt;- sits_train(\n  samples = samples_4classes_3bands,\n  ml_method = sits_rfor()\n  )\n\n# Classify the small area cube\ns2_cube_probs &lt;- sits_classify(\n  data = s2_reg_cube_ro,\n  ml_model = rfor_model,\n  output_dir = \"./cubes/02_class/\",\n  memsize = 15,\n  multicores = 5\n  )\n\n# Post-process the probability cube\ns2_cube_bayes &lt;- sits_smooth(\n  cube = s2_cube_probs,\n  output_dir = \"./cubes/02_class/\",\n  memsize = 16,\n  multicores = 4\n  )\n\n# Label the post-processed  probability cube\ns2_cube_label &lt;- sits_label_classification(\n  cube = s2_cube_bayes,\n  output_dir = \"./cubes/02_class/\",\n  memsize = 16,\n  multicores = 4\n  )\n\nplot(s2_cube_label)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#map-uncertainty",
    "href": "VT0007-deforestation-map.html#map-uncertainty",
    "title": "JNR Deforestation Risk Maps",
    "section": "Map uncertainty",
    "text": "Map uncertainty\nTo improve model performance, we estimate class uncertainty and plot these pixel error metrics. Results below reveal highest uncertainty levels in classification of wetland and water areas.\n\n# Calculate the uncertainty cube\ns2_cube_uncert &lt;- sits_uncertainty(\n  cube = s2_cube_bayes,\n  type = \"margin\",\n  output_dir = \"./cubes/03_error/\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_uncert)\n\nAs expected, the places of highest uncertainty are those covered by surface water or associated with wetlands. These places are likely to be misclassified. For this reason, sits provides sits_uncertainty_sampling(), which takes the uncertainty cube as its input and produces a tibble with locations in WGS84 with high uncertainty (Camara et al., n.d.).\n\n# Find samples with high uncertainty\nnew_samples &lt;- sits_uncertainty_sampling(\n  uncert_cube = s2_cube_uncert,\n  n = 20,\n  min_uncert = 0.5,\n  sampling_window = 10\n  )\n\n# View the location of the samples\nsits_view(new_samples)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#add-training-samples",
    "href": "VT0007-deforestation-map.html#add-training-samples",
    "title": "JNR Deforestation Risk Maps",
    "section": "Add training samples",
    "text": "Add training samples\nWe can then use these points of high-uncertainty as new samples to add to our current training dataset. Once we identify their feature classes and relabel them correctly, we append them to derive an augmented samples_round_2.\n\n# Label the new samples\nnew_samples$label &lt;- \"Wetland\"\n\n# Obtain the time series from the regularized cube\nnew_samples_ts &lt;- sits_get_data(\n  cube = s2_reg_cube_ro,\n  samples = new_samples\n  )\n\n# Add new class to original samples\nsamples_round_2 &lt;- dplyr::bind_rows(\n  samples_4classes_3bands,\n  new_samples_ts\n  )\n\n# Train a RF model with the new sample set\nrfor_model_v2 &lt;- sits_train(\n  samples = samples_round_2,\n  ml_method = sits_rfor()\n  )\n\n# Classify the small area cube\ns2_cube_probs_v2 &lt;- sits_classify(\n  data = s2_reg_cube_ro,\n  ml_model = rfor_model_v2,\n  output_dir = \"./cubes/02_class/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n  )\n\n# Post-process the probability cube\ns2_cube_bayes_v2 &lt;- sits_smooth(\n  cube = s2_cube_probs_v2,\n  output_dir = \"./cubes/04_smooth/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n  )\n\n# Label the post-processed  probability cube\ns2_cube_label_v2 &lt;- sits_label_classification(\n  cube = s2_cube_bayes_v2,\n  output_dir = \"./cubes/05_tuned/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n  )\n\n# Plot the second version of the classified cube\nplot(s2_cube_label_v2)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#remap-uncertainty",
    "href": "VT0007-deforestation-map.html#remap-uncertainty",
    "title": "JNR Deforestation Risk Maps",
    "section": "Remap uncertainty",
    "text": "Remap uncertainty\n\n# Calculate the uncertainty cube\ns2_cube_uncert_v2 &lt;- sits_uncertainty(\n  cube = s2_cube_bayes_v2,\n  type = \"margin\",\n  output_dir = \"./cubes/03_error/\",\n  version = \"v2\",\n  memsize = 16,\n  multicores = 4\n)\n\nplot(s2_cube_uncert_v2)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#accuracy-assessment",
    "href": "VT0007-deforestation-map.html#accuracy-assessment",
    "title": "JNR Deforestation Risk Maps",
    "section": "Accuracy assessment",
    "text": "Accuracy assessment\nTo select a validation subset of the map, sits recommends Cochran’s method for stratified random sampling (Cochran 1977). The method divides the population into homogeneous subgroups, or strata, and then applying random sampling within each stratum. Alternatively, ad-hoc parameterization is suggested as follows.\n\nro_sampling_design &lt;- sits_sampling_design(\n  cube = s2_cube_label_v2,\n  expected_ua = c(\n    \"Burned_Area\"       = 0.75,\n    \"Cleared_Area\"      = 0.70,\n    \"Forest\"            = 0.75,\n    \"Highly_Degraded\"   = 0.70,\n    \"Wetland\"           = 0.70\n  ),\n  alloc_options         = c(120, 100),\n  std_err               = 0.01,\n  rare_class_prop       = 0.1\n)\n# show sampling desing\nro_sampling_design"
  },
  {
    "objectID": "VT0007-deforestation-map.html#split-traintest-data",
    "href": "VT0007-deforestation-map.html#split-traintest-data",
    "title": "JNR Deforestation Risk Maps",
    "section": "Split train/test data",
    "text": "Split train/test data\n\nro_samples_sf &lt;- sits_stratified_sampling(\n  cube                  = s2_cube_label_v2,\n  sampling_design       = ro_sampling_design,\n  alloc                 = \"alloc_120\",\n  multicores            = 4,\n  shp_file              = \"./samples/ro_samples.shp\"\n)\n\nsf::st_write(ro_samples_sf,\n  \"./samples/ro_samples.csv\",\n  layer_options = \"GEOMETRY=AS_XY\",\n  append = FALSE # TRUE if editing existing sample\n)"
  },
  {
    "objectID": "VT0007-deforestation-map.html#confusion-matrix",
    "href": "VT0007-deforestation-map.html#confusion-matrix",
    "title": "JNR Deforestation Risk Maps",
    "section": "Confusion matrix",
    "text": "Confusion matrix\n\n# Calculate accuracy according to Olofsson's method\narea_acc &lt;- sits_accuracy(s2_cube_label_v2,\n  validation = ro_samples_sf,\n  multicores = 4\n)\n# Print the area estimated accuracy\narea_acc\n\n# Print the confusion matrix\narea_acc$error_matrix"
  },
  {
    "objectID": "VT0007-deforestation-map.html#times-series-visualization",
    "href": "VT0007-deforestation-map.html#times-series-visualization",
    "title": "JNR Deforestation Risk Maps",
    "section": "Times series visualization",
    "text": "Times series visualization\n\nsummary(as.data.frame(ro_samples_sf))"
  },
  {
    "objectID": "VT0007-deforestation-map.html#deforestation-binary-map",
    "href": "VT0007-deforestation-map.html#deforestation-binary-map",
    "title": "JNR Deforestation Risk Maps",
    "section": "Deforestation binary map",
    "text": "Deforestation binary map"
  },
  {
    "objectID": "VT0007-deforestation-map.html#deforestation-risk-map",
    "href": "VT0007-deforestation-map.html#deforestation-risk-map",
    "title": "JNR Deforestation Risk Maps",
    "section": "Deforestation risk map",
    "text": "Deforestation risk map"
  },
  {
    "objectID": "lib/python3.8/site-packages/pyzmq-26.2.0.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.8/site-packages/pyzmq-26.2.0.dist-info/licenses/LICENSE.html",
    "title": "VT0007",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2009-2012, Brian Granger, Min Ragan-Kelley\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "lib/python3.8/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "lib/python3.8/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "UAT for NbAgg backend.",
    "section": "",
    "text": "from imp import reload"
  },
  {
    "objectID": "lib/python3.8/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "href": "lib/python3.8/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "title": "UAT for NbAgg backend.",
    "section": "UAT for NbAgg backend.",
    "text": "UAT for NbAgg backend.\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\n\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)\n\n\nUAT 1 - Simple figure creation using pyplot\nShould produce a figure window which is interactive with the pan and zoom buttons. (Do not press the close button, but any others may be used).\n\nimport matplotlib.backends.backend_webagg_core\nreload(matplotlib.backends.backend_webagg_core)\n\nimport matplotlib.pyplot as plt\nplt.interactive(False)\n\nfig1 = plt.figure()\nplt.plot(range(10))\n\nplt.show()\n\n\n\nUAT 2 - Creation of another figure, without the need to do plt.figure.\nAs above, a new figure should be created.\n\nplt.plot([3, 2, 1])\nplt.show()\n\n\n\nUAT 3 - Connection info\nThe printout should show that there are two figures which have active CommSockets, and no figures pending show.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 4 - Closing figures\nClosing a specific figure instance should turn the figure into a plain image - the UI should have been removed. In this case, scroll back to the first figure and assert this is the case.\n\nplt.close(fig1)\nplt.close('all')\n\n\n\nUAT 5 - No show without plt.show in non-interactive mode\nSimply doing a plt.plot should not show a new figure, nor indeed update an existing one (easily verified in UAT 6). The output should simply be a list of Line2D instances.\n\nplt.plot(range(10))\n\n\n\nUAT 6 - Connection information\nWe just created a new figure, but didn’t show it. Connection info should no longer have “Figure 1” (as we closed it in UAT 4) and should have figure 2 and 3, with Figure 3 without any connections. There should be 1 figure pending.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 7 - Show of previously created figure\nWe should be able to show a figure we’ve previously created. The following should produce two figure windows.\n\nplt.show()\nplt.figure()\nplt.plot(range(5))\nplt.show()\n\n\n\nUAT 8 - Interactive mode\nIn interactive mode, creating a line should result in a figure being shown.\n\nplt.interactive(True)\nplt.figure()\nplt.plot([3, 2, 1])\n\nSubsequent lines should be added to the existing figure, rather than creating a new one.\n\nplt.plot(range(3))\n\nCalling connection_info in interactive mode should not show any pending figures.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\nDisable interactive mode again.\n\nplt.interactive(False)\n\n\n\nUAT 9 - Multiple shows\nUnlike most of the other matplotlib backends, we may want to see a figure multiple times (with or without synchronisation between the views, though the former is not yet implemented). Assert that plt.gcf().canvas.manager.reshow() results in another figure window which is synchronised upon pan & zoom.\n\nplt.gcf().canvas.manager.reshow()\n\n\n\nUAT 10 - Saving notebook\nSaving the notebook (with CTRL+S or File-&gt;Save) should result in the saved notebook having static versions of the figures embedded within. The image should be the last update from user interaction and interactive plotting. (check by converting with ipython nbconvert &lt;notebook&gt;)\n\n\nUAT 11 - Creation of a new figure on second show\nCreate a figure, show it, then create a new axes and show it. The result should be a new figure.\nBUG: Sometimes this doesn’t work - not sure why (@pelson).\n\nfig = plt.figure()\nplt.axes()\nplt.show()\n\nplt.plot([1, 2, 3])\nplt.show()\n\n\n\nUAT 12 - OO interface\nShould produce a new figure and plot it.\n\nfrom matplotlib.backends.backend_nbagg import new_figure_manager,show\n\nmanager = new_figure_manager(1000)\nfig = manager.canvas.figure\nax = fig.add_subplot(1,1,1)\nax.plot([1,2,3])\nfig.show()"
  },
  {
    "objectID": "lib/python3.8/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "lib/python3.8/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "UAT for NbAgg backend.",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "lib/python3.8/site-packages/pandas-2.0.3.dist-info/AUTHORS.html",
    "href": "lib/python3.8/site-packages/pandas-2.0.3.dist-info/AUTHORS.html",
    "title": "About the Copyright Holders",
    "section": "",
    "text": "About the Copyright Holders\n\nCopyright (c) 2008-2011 AQR Capital Management, LLC\nAQR Capital Management began pandas development in 2008. Development was led by Wes McKinney. AQR released the source under this license in 2009.\nCopyright (c) 2011-2012, Lambda Foundry, Inc.\nWes is now an employee of Lambda Foundry, and remains the pandas project lead.\nCopyright (c) 2011-2012, PyData Development Team\nThe PyData Development Team is the collection of developers of the PyData project. This includes all of the PyData sub-projects, including pandas. The core team that coordinates development on GitHub can be found here: https://github.com/pydata.\n\nFull credits for pandas contributors can be found in the documentation.\n\n\nOur Copyright Policy\nPyData uses a shared copyright model. Each contributor maintains copyright over their contributions to PyData. However, it is important to note that these contributions are typically only changes to the repositories. Thus, the PyData source code, in its entirety, is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire PyData Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change when they commit the change to one of the PyData repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n#-----------------------------------------------------------------------------\n# Copyright (c) 2012, PyData Development Team\n# All rights reserved.\n#\n# Distributed under the terms of the BSD Simplified License.\n#\n# The full license is in the LICENSE file, distributed with this software.\n#-----------------------------------------------------------------------------\nOther licenses can be found in the LICENSES directory.\n\n\nLicense\npandas is distributed under a 3-clause (“Simplified” or “New”) BSD license. Parts of NumPy, SciPy, numpydoc, bottleneck, which all have BSD-compatible licenses, are included. Their licenses follow the pandas license."
  },
  {
    "objectID": "lib/python3.8/site-packages/idna-3.10.dist-info/LICENSE.html",
    "href": "lib/python3.8/site-packages/idna-3.10.dist-info/LICENSE.html",
    "title": "VT0007",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2024, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "lib/python3.8/site-packages/httpx-0.28.1.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.8/site-packages/httpx-0.28.1.dist-info/licenses/LICENSE.html",
    "title": "VT0007",
    "section": "",
    "text": "Copyright © 2019, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "lib/python3.8/site-packages/httpcore-1.0.7.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.8/site-packages/httpcore-1.0.7.dist-info/licenses/LICENSE.html",
    "title": "VT0007",
    "section": "",
    "text": "Copyright © 2020, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "lib/python3.8/site-packages/soupsieve-2.6.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.8/site-packages/soupsieve-2.6.dist-info/licenses/LICENSE.html",
    "title": "VT0007",
    "section": "",
    "text": "MIT License\nCopyright (c) 2018 - 2024 Isaac Muse isaacmuse@gmail.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  }
]